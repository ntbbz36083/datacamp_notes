{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use concat, replicate, len\n",
    "SELECT \n",
    "\t-- Concat the strings\n",
    "\tconcat(\n",
    "\t\tcarrier_code, \n",
    "\t\t' - ', \n",
    "      \t-- Replicate zeros\n",
    "\t\tReplicate('0', 9 - len(registration_code)), \n",
    "\t\tregistration_code, \n",
    "\t\t', ', \n",
    "\t\tairport_code)\n",
    "\tAS registration_code\n",
    "FROM flight_statistics\n",
    "-- Filter registers with more than 100 delays\n",
    "WHERE delayed > 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use concat, format\n",
    "SELECT \n",
    "    -- Concat the strings\n",
    "\tconcat(\n",
    "\t\tcarrier_code, \n",
    "\t\t' - ', \n",
    "        -- Format the code\n",
    "\t\tformat(cast(registration_code AS INT), '0000000'),\n",
    "\t\t', ', \n",
    "\t\tairport_code\n",
    "\t) AS registration_code\n",
    "FROM flight_statistics\n",
    "-- Filter registers with more than 100 delays\n",
    "WHERE delayed > 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#soundex() difference()\n",
    "SELECT \n",
    "    -- First name and surname of the statisticians\n",
    "\tDISTINCT S1.statistician_name, S1.statistician_surname\n",
    "-- Join flight_statistics with itself\n",
    "FROM flight_statistics S1 INNER JOIN flight_statistics S2 \n",
    "\t-- The SOUNDEX result of the first name and surname have to be the same\n",
    "\tON SOUNDEX(S1.statistician_name) = SOUNDEX(S2.statistician_name) \n",
    "\tAND SOUNDEX(S1.statistician_surname) = SOUNDEX(S2.statistician_surname) \n",
    "-- The texts of the first name or the texts of the surname have to be different\n",
    "WHERE S1.statistician_name <> S2.statistician_name\n",
    "\tOR S1.statistician_surname <> S2.statistician_surname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT \n",
    "    -- First name and surnames of the statisticians\n",
    "\tDISTINCT S1.statistician_name, S1.statistician_surname\n",
    "-- Join flight_statistics with itself\n",
    "FROM flight_statistics S1 INNER JOIN flight_statistics S2 \n",
    "\t-- The DIFFERENCE of the first name and surname has to be equals to 4\n",
    "\tON difference(S1.statistician_name, S2.statistician_name) = 4\n",
    "\tAND difference(S1.statistician_surname, S2.statistician_surname) = 4\n",
    "-- The texts of the first name or the texts of the surname have to be different\n",
    "WHERE S1.statistician_name <> S2.statistician_name\n",
    "\tOR S1.statistician_surname <> S2.statistician_surname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COALESCE, if first 2 are null, then display 3rd value\n",
    "SELECT\n",
    "airport_code,\n",
    "airport_name,\n",
    "-- Replace the missing values\n",
    "COALESCE(airport_city, airport_state, 'Unknown') AS location\n",
    "FROM airports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#row_number()\n",
    "WITH cte AS (\n",
    "    SELECT *, \n",
    "        ROW_NUMBER() OVER (\n",
    "            PARTITION BY \n",
    "                airport_code, \n",
    "                carrier_code, \n",
    "                registration_date\n",
    "\t\t\tORDER BY \n",
    "                airport_code, \n",
    "                carrier_code, \n",
    "                registration_date\n",
    "        ) row_num\n",
    "    FROM flight_statistics\n",
    ")\n",
    "SELECT * FROM cte\n",
    "-- Exclude duplicates\n",
    "WHERE row_num =1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use convert to convert date\n",
    "SELECT \n",
    "    airport_code,\n",
    "    carrier_code,\n",
    "    canceled, \n",
    "    airport_code, \n",
    "    -- Convert the registration_date to a DATE and print it in mm/dd/yyyy format\n",
    "    convert(VARCHAR(10), cast(registration_date AS DATE), 101) AS registration_date\n",
    "FROM flight_statistics \n",
    "-- Convert the registration_date to mm/dd/yyyy format\n",
    "WHERE convert(VARCHAR(10), cast(registration_date AS DATE), 101) \n",
    "\t-- Filter the first semester of 2014 in mm/dd/yyyy format \n",
    "\tBETWEEN '01/01/2014' AND '06/30/2014'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use format to convert date\n",
    "SELECT \n",
    "\tpilot_code,\n",
    "\tpilot_name,\n",
    "\tpilot_surname,\n",
    "\tcarrier_code,\n",
    "    -- Convert the entry_date to a DATE and print it in dd/MM/yyyy format\n",
    "\tformat(cast(entry_date AS DATE), 'dd/MM/yyyy') AS entry_date\n",
    "from pilots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# substring and chaindex\n",
    "SELECT \n",
    "\tclient_name,\n",
    "\tclient_surname,\n",
    "    -- Extract the name of the city\n",
    "\tSUBSTRING(city_state, 1, CHARINDEX(', ', city_state) - 1) AS city,\n",
    "    -- Extract the name of the state\n",
    "    SUBSTRING(city_state, CHARINDEX(', ', city_state) + 1, LEN(city_state)) AS state\n",
    "FROM clients_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pivot and unpivot\n",
    "#pivot turns rows to columns\n",
    "#unpivot turns columns to rows\n",
    "SELECT\n",
    "\tyear_of_sale,\n",
    "    -- Select the pivoted columns\n",
    "\tnotebooks, \n",
    "\tpencils, \n",
    "\tcrayons\n",
    "FROM\n",
    "   (SELECT \n",
    "\t\tSUBSTRING(product_name_units, 1, charindex('-', product_name_units)-1) product_name, \n",
    "\t\tCAST(SUBSTRING(product_name_units, charindex('-', product_name_units)+1, len(product_name_units)) AS INT) units,\t\n",
    "\t\tyear_of_sale\n",
    "\tFROM paper_shop_monthly_sales) sales\n",
    "-- Sum the units for column that contains the values that will be column headers\n",
    "PIVOT (SUM(units) FOR product_name IN (notebooks, pencils, crayons))\n",
    "-- Give the alias name\n",
    "AS paper_shop_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT * FROM pivot_sales\n",
    "-- Use the operator to convert columns into rows\n",
    "unpivot\n",
    "\t-- The resulting column that will contain the turned columns into rows\n",
    "\t(units FOR product_name IN (notebooks, pencils, crayons))\n",
    "-- Give the alias name\n",
    "AS unpivot_sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list is immuteable\n",
    "// Initialize a list with an element for each round's prize\n",
    "val prizes = List(10,15,20,25,30)\n",
    "println(prizes)\n",
    "\n",
    "// Prepend to prizes to add another round and prize\n",
    "val newPrizes = 5::prizes\n",
    "println(newPrizes)\n",
    "\n",
    "// Initialize a list with an element each round's prize\n",
    "val prizes = 10::15::20::25::30::Nil\n",
    "println(prizes)\n",
    "\n",
    "// The original NTOA and EuroTO venue lists\n",
    "val venuesNTOA = List(\"The Grand Ballroom\", \"Atlantis Casino\", \"Doug's House\")\n",
    "val venuesEuroTO = \"Five Seasons Hotel\" :: \"The Electric Unicorn\" :: Nil\n",
    "\n",
    "// Concatenate the North American and European venues\n",
    "val venuesTOWorld = venuesNTOA ::: venuesEuroTO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3', region_name='us-east-1', \n",
    "                        # Set up AWS credentials \n",
    "                        aws_access_key_id=AWS_KEY_ID, \n",
    "                         aws_secret_access_key=AWS_SECRET)\n",
    "# List the buckets\n",
    "buckets = s3.list_buckets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Create boto3 client to S3\n",
    "s3 = boto3.client('s3', region_name='us-east-1', \n",
    "                         aws_access_key_id=AWS_KEY_ID, \n",
    "                         aws_secret_access_key=AWS_SECRET)\n",
    "\n",
    "# Create the buckets\n",
    "response_staging = s3.create_bucket(Bucket='gim-staging')\n",
    "response_processed = s3.create_bucket(Bucket='gim-processed')\n",
    "response_test = s3.create_bucket(Bucket='gim-test')\n",
    "\n",
    "# Print out the response\n",
    "print(response_staging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list_buckets response\n",
    "response = s3.list_buckets()\n",
    "\n",
    "# Iterate over Buckets from .list_buckets() response\n",
    "for bucket in response['Buckets']:\n",
    "  \n",
    "  \t# Print the Name for each bucket\n",
    "    print(bucket['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the gim-test bucket\n",
    "s3.delete_bucket(Bucket='gim-test')\n",
    "\n",
    "# Get the list_buckets response\n",
    "response = s3.list_buckets()\n",
    "\n",
    "# Print each Buckets Name\n",
    "for bucket in response['Buckets']:\n",
    "    print(bucket['Name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list_buckets response\n",
    "response = s3.list_buckets()\n",
    "\n",
    "# Delete all the buckets with 'gim', create replacements.\n",
    "for bucket in response['Buckets']:\n",
    "  if 'gim' in bucket['Name']:\n",
    "      s3.delete_bucket(Bucket=bucket['Name'])\n",
    "    \n",
    "s3.create_bucket(Bucket='gid-staging')\n",
    "s3.create_bucket(Bucket='gid-processed')\n",
    "  \n",
    "# Print bucket listing after deletion\n",
    "response = s3.list_buckets()\n",
    "for bucket in response['Buckets']:\n",
    "    print(bucket['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload final_report.csv to gid-staging\n",
    "s3.upload_file(Bucket='gid-staging',\n",
    "              # Set filename and key\n",
    "               Filename='final_report.csv', \n",
    "               Key='2019/final_report_01_01.csv')\n",
    "\n",
    "# Get object metadata and print it\n",
    "response = s3.head_object(Bucket='gid-staging', \n",
    "                       Key='2019/final_report_01_01.csv')\n",
    "\n",
    "# Print the size of the uploaded object\n",
    "print(response['ContentLength'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List only objects that start with '2018/final_'\n",
    "response = s3.list_objects(Bucket='gid-staging', \n",
    "                           Prefix='2018/final_')\n",
    "\n",
    "# Iterate over the objects\n",
    "if 'Contents' in response:\n",
    "  for obj in response['Contents']:\n",
    "      # Delete the object\n",
    "      s3.delete_object(Bucket='gid-staging', Key=obj['Key'])\n",
    "\n",
    "# Print the keys of remaining objects in the bucket\n",
    "response = s3.list_objects(Bucket='gid-staging')\n",
    "\n",
    "for obj in response['Contents']:\n",
    "  \tprint(obj['Key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the final_report.csv to gid-staging bucket\n",
    "s3.upload_file(\n",
    "  # Complete the filename\n",
    "  Filename='./final_report.csv', \n",
    "  # Set the key and bucket\n",
    "  Key='2019/final_report_2019_02_20.csv', \n",
    "  Bucket='gid-staging',\n",
    "  # During upload, set ACL to public-read\n",
    "  ExtraArgs = {\n",
    "    'ACL': 'public-read'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List only objects that start with '2019/final_'\n",
    "response = s3.list_objects(\n",
    "    Bucket='gid-staging', Prefix='2019/final_')\n",
    "\n",
    "# Iterate over the objects\n",
    "for obj in response['Contents']:\n",
    "\n",
    "    # Give each object ACL of public-read\n",
    "    s3.put_object_acl(Bucket='gid-staging', \n",
    "                      Key=obj['Key'], \n",
    "                      ACL='public-read')\n",
    "    \n",
    "    # Print the Public Object URL for each object\n",
    "    print(\"https://{}.s3.amazonaws.com/{}\".format( 'gid-staging', obj['Key']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate presigned_url for the uploaded object\n",
    "share_url = s3.generate_presigned_url(\n",
    "  # Specify allowable operations\n",
    "  ClientMethod='get_object',\n",
    "  # Set the expiration time\n",
    "  ExpiresIn=3600,\n",
    "  # Set bucket and shareable object's name\n",
    "  Params={'Bucket': 'gid-staging','Key': 'final_report.csv'}\n",
    ")\n",
    "\n",
    "# Print out the presigned URL\n",
    "print(share_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list =  [ ] \n",
    "\n",
    "for file in response['Contents']:\n",
    "    # For each file in response load the object from S3\n",
    "    obj = s3.get_object(Bucket='gid-requests', Key=file['Key'])\n",
    "    # Load the object's StreamingBody with pandas\n",
    "    obj_df = pd.read_csv(obj['Body'])\n",
    "    # Append the resulting DataFrame to list\n",
    "    df_list.append(obj_df)\n",
    "\n",
    "# Concat all the DataFrames with pandas\n",
    "df = pd.concat(df_list)\n",
    "\n",
    "# Preview the resulting DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an HTML table with no border and selected columns\n",
    "services_df.to_html('./services_no_border.html',\n",
    "           # Keep specific columns only\n",
    "           columns=['service_name', 'link'],\n",
    "           # Set border\n",
    "           border=0)\n",
    "\n",
    "# Generate an html table with border and all columns.\n",
    "services_df.to_html('./services_border_all_columns.html', \n",
    "           border=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the lines.html file to S3\n",
    "s3.upload_file(Filename='lines.html', \n",
    "               # Set the bucket name\n",
    "               Bucket='datacamp-public', Key='index.html',\n",
    "               # Configure uploaded file\n",
    "               ExtraArgs = {\n",
    "                 # Set proper content type\n",
    "                 'ContentType':'text/html',\n",
    "                 # Set proper ACL\n",
    "                 'ACL': 'public-read'})\n",
    "\n",
    "# Print the S3 Public Object URL for the new file.\n",
    "print(\"http://{}.s3.amazonaws.com/{}\".format('datacamp-public', 'index.html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [] \n",
    "\n",
    "# Load each object from s3\n",
    "for file in request_files:\n",
    "    s3_day_reqs = s3.get_object(Bucket='gid-requests', \n",
    "                                Key=file['Key'])\n",
    "    # Read the DataFrame into pandas, append it to the list\n",
    "    day_reqs = pd.read_csv(s3_day_reqs['Body'])\n",
    "    df_list.append(day_reqs)\n",
    "\n",
    "# Concatenate all the DataFrames in the list\n",
    "all_reqs = pd.concat(df_list)\n",
    "\n",
    "# Preview the DataFrame\n",
    "all_reqs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write agg_df to a CSV and HTML file with no border\n",
    "agg_df.to_csv('./feb_final_report.csv')\n",
    "agg_df.to_html('./feb_final_report.html', border=0)\n",
    "\n",
    "# Upload the generated CSV to the gid-reports bucket\n",
    "s3.upload_file(Filename='./feb_final_report.csv', \n",
    "\tKey='2019/feb/final_report.html', Bucket='gid-reports',\n",
    "    ExtraArgs = {'ACL': 'public-read'})\n",
    "\n",
    "# Upload the generated HTML to the gid-reports bucket\n",
    "s3.upload_file(Filename='./feb_final_report.html', \n",
    "\tKey='2019/feb/final_report.html', Bucket='gid-reports',\n",
    "    ExtraArgs = {'ContentType': 'text/html', \n",
    "                 'ACL': 'public-read'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the gid-reports bucket objects starting with 2019/\n",
    "objects_list = s3.list_objects(Bucket='gid-reports', Prefix='2019/')\n",
    "\n",
    "# Convert the response contents to DataFrame\n",
    "objects_df = pd.DataFrame(objects_list['Contents'])\n",
    "\n",
    "# Create a column \"Link\" that contains Public Object URL\n",
    "base_url = \"http://gid-reports.s3.amazonaws.com/\"\n",
    "objects_df['Link'] = base_url + objects_df['Key']\n",
    "\n",
    "# Preview the resulting DataFrame\n",
    "objects_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write objects_df to an HTML file\n",
    "objects_df.to_html('report_listing.html',\n",
    "    # Set clickable links\n",
    "    render_links=True,\n",
    "\t# Isolate the columns\n",
    "    columns=['Link', 'LastModified', 'Size'])\n",
    "\n",
    "# Overwrite index.html key by uploading the new file\n",
    "s3.upload_file(\n",
    "  Filename='./report_listing.html', Key='index.html', \n",
    "  Bucket='gid-reports',\n",
    "  ExtraArgs = {\n",
    "    'ContentType': 'text/html', \n",
    "    'ACL': 'public-read'\n",
    "  })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize boto3 client for SNS\n",
    "sns = boto3.client('sns', \n",
    "                   region_name='us-east-1', \n",
    "                   aws_access_key_id=AWS_KEY_ID, \n",
    "                   aws_secret_access_key=AWS_SECRET)\n",
    "\n",
    "# Create the city_alerts topic\n",
    "response = sns.create_topic(Name=\"city_alerts\")\n",
    "c_alerts_arn = response['TopicArn']\n",
    "\n",
    "# Re-create the city_alerts topic using a oneliner\n",
    "c_alerts_arn_1 = sns.create_topic(Name='city_alerts')['TopicArn']\n",
    "\n",
    "# Compare the two to make sure they match\n",
    "print(c_alerts_arn == c_alerts_arn_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of departments\n",
    "departments = ['trash', 'streets', 'water']\n",
    "\n",
    "for dept in departments:\n",
    "  \t# For every department, create a general topic\n",
    "    sns.create_topic(Name=\"{}_general\".format(dept))\n",
    "    \n",
    "    # For every department, create a critical topic\n",
    "    sns.create_topic(Name=\"{}_critical\".format(dept))\n",
    "\n",
    "# Print all the topics in SNS\n",
    "response = sns.list_topics()\n",
    "print(response['Topics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current list of topics\n",
    "topics = sns.list_topics()['Topics']\n",
    "\n",
    "for topic in topics:\n",
    "  # For each topic, if it is not marked critical, delete it\n",
    "  if \"critical\" not in topic['TopicArn']:\n",
    "    sns.delete_topic(TopicArn=topic['TopicArn'])\n",
    "    \n",
    "# Print the list of remaining critical topics\n",
    "print(sns.list_topics()['Topics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subscribe Elena's phone number to streets_critical topic\n",
    "resp_sms = sns.subscribe(\n",
    "  TopicArn = str_critical_arn, \n",
    "  Protocol='sms', Endpoint=\"+16196777733\")\n",
    "\n",
    "# Print the SubscriptionArn\n",
    "print(resp_sms['SubscriptionArn'])\n",
    "\n",
    "# Subscribe Elena's email to streets_critical topic.\n",
    "resp_email = sns.subscribe(\n",
    "  TopicArn = str_critical_arn, \n",
    "  Protocol='email', Endpoint=\"eblock@sandiegocity.gov\")\n",
    "\n",
    "# Print the SubscriptionArn\n",
    "print(resp_email['SubscriptionArn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each email in contacts, create subscription to street_critical\n",
    "for email in contacts['Email']:\n",
    "  sns.subscribe(TopicArn = str_critical_arn,\n",
    "                # Set channel and recipient\n",
    "                Protocol = 'email',\n",
    "                Endpoint = email)\n",
    "\n",
    "# List subscriptions for streets_critical topic, convert to DataFrame\n",
    "response = sns.list_subscriptions_by_topic(\n",
    "  TopicArn = str_critical_arn)\n",
    "subs = pd.DataFrame(response['Subscriptions'])\n",
    "\n",
    "# Preview the DataFrame\n",
    "subs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List subscriptions for streets_critical topic.\n",
    "response = sns.list_subscriptions_by_topic(\n",
    "  TopicArn = str_critical_arn)\n",
    "\n",
    "# For each subscription, if the protocol is SMS, unsubscribe\n",
    "for sub in response['Subscriptions']:\n",
    "  if sub['Protocol'] == 'sms':\n",
    "\t  sns.unsubscribe(SubscriptionArn=sub['SubscriptionArn'])\n",
    "\n",
    "# List subscriptions for streets_critical topic in one line\n",
    "subs = sns.list_subscriptions_by_topic(\n",
    "  TopicArn=str_critical_arn)['Subscriptions']\n",
    "\n",
    "# Print the subscriptions\n",
    "print(subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there are over 100 potholes, create a message\n",
    "if streets_v_count > 100:\n",
    "  # The message should contain the number of potholes.\n",
    "  message = \"There are {} potholes!\".format(streets_v_count)\n",
    "  # The email subject should also contain number of potholes\n",
    "  subject = \"Latest pothole count is {}\".format(streets_v_count)\n",
    "\n",
    "  # Publish the email to the streets_critical topic\n",
    "  sns.publish(\n",
    "    TopicArn = str_critical_arn,\n",
    "    # Set subject and message\n",
    "    Message = message,\n",
    "    Subject = subject\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through every row in contacts\n",
    "for idx, row in contacts.iterrows():\n",
    "    \n",
    "    # Publish an ad-hoc sms to the user's phone number\n",
    "    response = sns.publish(\n",
    "        # Set the phone number\n",
    "        PhoneNumber = str(row['Phone']),\n",
    "        # The message should include the user's name\n",
    "        Message = 'Hello {}'.format(row['Name'])\n",
    "    )\n",
    "   \n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dept_arns = {} \n",
    "\n",
    "for dept in departments:\n",
    "  # For each deparment, create a critical topic\n",
    "  critical = sns.create_topic(Name=\"{}_critical\".format(dept))\n",
    "  # For each department, create an extreme topic\n",
    "  extreme = sns.create_topic(Name=\"{}_extreme\".format(dept))\n",
    "  # Place the created TopicARNs into a dictionary \n",
    "  dept_arns['{}_critical'.format(dept)] = critical['TopicArn']\n",
    "  dept_arns['{}_extreme'.format(dept)] = extreme['TopicArn']\n",
    "\n",
    "# Print the filled dictionary.\n",
    "print(dept_arns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, user_row in contacts.iterrows():\n",
    "  # Get topic names for the users's dept\n",
    "  critical_tname = '{}_critical'.format(user_row['Department'])\n",
    "  extreme_tname = '{}_extreme'.format(user_row['Department'])\n",
    "  \n",
    "  # Get or create the TopicArns for a user's department.\n",
    "  critical_arn = sns.create_topic(Name=critical_tname)['TopicArn']\n",
    "  extreme_arn = sns.create_topic(Name=extreme_tname)['TopicArn']\n",
    "  \n",
    "  # Subscribe each users email to the critical Topic\n",
    "  sns.subscribe(TopicArn = critical_arn, \n",
    "                Protocol='email', Endpoint=user_row['Email'])\n",
    "  # Subscribe each users phone number for the extreme Topic\n",
    "  sns.subscribe(TopicArn = extreme_arn, \n",
    "                Protocol='sms', Endpoint=str(user_row['Phone']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if vcounts['water'] > 100:\n",
    "  # If over 100 water violations, publish to water_critical\n",
    "  sns.publish(\n",
    "    TopicArn = dept_arns['water_critical'],\n",
    "    Message = \"{} water issues\".format(vcounts['water']),\n",
    "    Subject = \"Help fix water violations NOW!\")\n",
    "\n",
    "if vcounts['water'] > 300:\n",
    "  # If over 300 violations, publish to water_extreme\n",
    "  sns.publish(\n",
    "    TopicArn = dept_arns['water_extreme'],\n",
    "    Message = \"{} violations! RUN!\".format(vcounts['water']),\n",
    "    Subject = \"THIS IS BAD.  WE ARE FLOODING!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rekognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Rekognition client to detect labels\n",
    "image1_response = rekog.detect_labels(\n",
    "    # Specify the image as an S3Object; Return one label\n",
    "    Image=image1, MaxLabels=1)\n",
    "\n",
    "# Print the labels\n",
    "print(image1_response['Labels'])\n",
    "\n",
    "# Use Rekognition client to detect labels\n",
    "image2_response = rekog.detect_labels(\n",
    "    # Specify the image as an S3Object; Return one label\n",
    "    Image=image2, MaxLabels=1)\n",
    "\n",
    "# Print the labels\n",
    "print(image2_response['Labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty counter variable\n",
    "cats_count = 0\n",
    "# Iterate over the labels in the response\n",
    "for label in response['Labels']:\n",
    "    # Find the cat label, look over the detected instances\n",
    "    if label['Name'] == 'Cat':\n",
    "        for instance in label['Instances']:\n",
    "            # Only count instances with confidence > 85\n",
    "            if (instance['Confidence'] > 85):\n",
    "                cats_count += 1\n",
    "# Print count of cats\n",
    "print(cats_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## translate/detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each dataframe row\n",
    "for index, row in dumping_df.iterrows():\n",
    "    # Get the public description field\n",
    "    description =dumping_df.loc[index, 'public_description']\n",
    "    if description != '':\n",
    "        # Detect language in the field content\n",
    "        resp = comprehend.detect_dominant_language(Text=description)\n",
    "        # Assign the top choice language to the lang column.\n",
    "        dumping_df.loc[index, 'lang'] = resp['Languages'][0]['LanguageCode']\n",
    "        \n",
    "# Count the total number of spanish posts\n",
    "spanish_post_ct = len(dumping_df[dumping_df.lang == 'es'])\n",
    "# Print the result\n",
    "print(\"{} posts in Spanish\".format(spanish_post_ct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in dumping_df.iterrows():\n",
    "  \t# Get the public_description into a variable\n",
    "    description = dumping_df.loc[index, 'public_description']\n",
    "    if description != '':\n",
    "      \t# Translate the public description\n",
    "        resp = translate.translate_text(\n",
    "            Text=description, \n",
    "            SourceLanguageCode='auto', TargetLanguageCode='en')\n",
    "        # Store original language in original_lang column\n",
    "        dumping_df.loc[index, 'original_lang'] = resp['SourceLanguageCode']\n",
    "        # Store the translation in the translated_desc column\n",
    "        dumping_df.loc[index, 'translated_desc'] = resp['TranslatedText']\n",
    "# Preview the resulting DataFrame\n",
    "dumping_df = dumping_df[['service_request_id', 'original_lang', 'translated_desc']]\n",
    "dumping_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in dumping_df.iterrows():\n",
    "  \t# Get the translated_desc into a variable\n",
    "    description = dumping_df.loc[index, 'public_description']\n",
    "    if description != '':\n",
    "      \t# Get the detect_sentiment response\n",
    "        response = comprehend.detect_sentiment(\n",
    "          Text=description, \n",
    "          LanguageCode='en')\n",
    "        # Get the sentiment key value into sentiment column\n",
    "        dumping_df.loc[index, 'sentiment'] = response['Sentiment']\n",
    "# Preview the dataframe\n",
    "dumping_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in scooter_requests.iterrows():\n",
    "  \t# For every DataFrame row\n",
    "    desc = scooter_requests.loc[index, 'public_description']\n",
    "    if desc != '':\n",
    "      \t# Detect the dominant language\n",
    "        resp = comprehend.detect_dominant_language(Text=desc)\n",
    "        lang_code = resp['Languages'][0]['LanguageCode']\n",
    "        scooter_requests.loc[index, 'lang'] = lang_code\n",
    "        # Use the detected language to determine sentiment\n",
    "        scooter_requests.loc[index, 'sentiment'] = comprehend.detect_sentiment(\n",
    "          Text=desc, \n",
    "          LanguageCode=lang_code)['Sentiment']\n",
    "# Perform a count of sentiment by group.\n",
    "counts = scooter_requests.groupby(['sentiment', 'lang']).count()\n",
    "counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get topic ARN for scooter notifications\n",
    "topic_arn = sns.create_topic(Name='scooter_notifications')['TopicArn']\n",
    "\n",
    "for index, row in scooter_requests.iterrows():\n",
    "    # Check if notification should be sent\n",
    "    if (row['sentiment'] == 'NEGATIVE') & (row['img_scooter'] == 1):\n",
    "        # Construct a message to publish to the scooter team.\n",
    "        message = \"Please remove scooter at {}, {}. Description: {}\".format(\n",
    "            row['long'], row['lat'], row['public_description'])\n",
    "\n",
    "        # Publish the message to the topic!\n",
    "        sns.publish(TopicArn = topic_arn,\n",
    "                    Message = message, \n",
    "                    Subject = \"Scooter Alert\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
